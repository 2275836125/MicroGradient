# PeriodicNet
This repository contains an algorithm designed to predict periodic variations. The algorithm uses gradient descent to fit a sinusoidal model to time series data.
## Introduction
In either fecal micoribal treansplantation (FMT) for human, or multiple microbiome engraftment in fermentaion process, or other complex microbial community manipulation, we will encounter a context in which a "designed" microbial community is injected into a natual microbial community, and could lead to a change of the original microbial community, usually for the good of the host. Please formally define this process and model, and name this process as microbiome engraftment(ME).<br/>
We developed "PeriodicNet," a novel model for analyzing cyclical time series data from the ME process, using findings from  <a href="https://github.com/HUST-NingKang-Lab/Moutai-SME" title="超链接title">Moutai SME project</a>. PeriodicNet confirms the periodic nature of ME-induced effects and effectively captures their underlying patterns.

## Explanation
<div style="text-align: center;">
  <img src="images/figure1.png" alt="Descriptive text" style="width: 100%;"/>
  <p style="font-style: italic;">Fig1 (A) The microbiome is regularly stimulated, assuming that microbiome changes periodically (B)The microbiome was identified by 16s sequencing (C)Calculate differences of the microbiome (D)Gradient descent was used to optimise the model and RMSE is the loss function (E)Gradient descent to fit parameters</p>
</div>
An application of the PeriodicNet to the prediction of trends in cyclically changing microbiomes Fig.1(A). We wanted to predict changes in the microbiome, and using Bray-Curtis Dissimilarity to measure distances between microbiomes. Considering the periodicity of microbiome variation
, we used a periodic function to predict microbiome variation
 Fig.1(E).RMSE is a common loss function used in regression problems, which measures the average magnitude of the errors between the predicted values and the actual values Fig.1(F). The model adopts the random initialization and the parameters were updated by gradient descent.

## Download
Download MicroGradient using git:
```shell
git clone https://github.com/2275836125/MicroGradient.git
```
## Usage
Example: Fit a sinusoidal model to the time series data of microbiome represented by Bray-Curtis (BC) distances.
1. **Data Preparation:** Organize your microbiome data into a matrix format where rows represent microbial species and columns represent days. Denote this matrix as $M$, where $M_{ij}$ represents the abundance of microbial species $i$ on day $j$.

2. **Calculate Bray-Curtis Dissimilarity:**

   The Bray-Curtis Dissimilarity between two microbiome (i.e., two different days in your case) is calculated using the formula:
```math
   \text{Bray-Curtis} = \frac{\sum_i |X_i - Y_i|}{\sum_i (X_i + Y_i)} 
```
   Where:
   - $X_i$ is the abundance of microbial species $i$ in sample 1.
   - $Y_i$ is the abundance of microbial species $i$ in sample 2.
   - The summation is over all microbial species.

3. **Define the Objective Function**: The objective is to minimize the error between the actual periodic time series data and the predicted values generated by the model. Denote the time series data as $Y = \{y_1, y_2, ..., y_n\}$ and the predicted values as $\hat{Y} = \{\hat{y}_1, \hat{y}_2, ..., \hat{y}_n\}$. The error can be represented using a loss function such as Root Mean Square Error (RMSE):
```math
   \text{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
```
4. **Model Architecture**: Use a simple model that consists of a periodic function. We'll use a sinusoidal function for this purpose:
```math
    \hat{y}_i = A \cdot \sin(\omega t_i + \phi) + b 
```
   Where:
   - $A$ is the amplitude.
   - $\omega$ is the angular frequency (related to the frequency of stimuli affecting the microbiome, a fixed parameter).
   - $t_i$ is the time index.
   - $\phi$ is the phase shift.
   - $b$ is the bias term.

5. **Initialize Parameters**: Initialize the parameters randomly or with some sensible initial values.

6. **Gradient Descent**: Update the parameters iteratively to minimize the objective function. Compute the gradients of the loss function with respect to each parameter and update the parameters accordingly. The update rule for each parameter can be formulated as follows:
```math
 \theta_{\text{new}} = \theta_{\text{old}} - \alpha \frac{\partial \text{MSE}}{\partial \theta_{\text{old}}} 
```
   Where $\theta$ represents any of the parameters (amplitude, angular frequency, phase shift, or bias), and $\alpha$ is the learning rate.

7. **Prediction**: Once the parameters are optimized, use the model to predict future values of the time series.

8. **Evaluate Model Performance**: Evaluate the model's performance using metrics like Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), or other relevant metrics on a validation dataset.

9. **Fine-tuning**: If necessary, fine-tune hyperparameters such as learning rate, model architecture, or regularization strength to improve performance.
